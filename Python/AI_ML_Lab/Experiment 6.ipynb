{"cells":[{"cell_type":"markdown","id":"cf9bee12-a273-4276-ac0b-19ed7ee39288","metadata":{"id":"cf9bee12-a273-4276-ac0b-19ed7ee39288"},"source":["# Introduction to Data Preprocessing\n","\n","- Real-world datasets are often incomplete, inconsistent, or messy.\n","- Data may contain:\n","  - Missing values (empty fields)\n","  - Outliers (extreme or unusual values)\n","  - Errors or inconsistencies\n","- **Data preprocessing** is the process of cleaning and transforming data to make it suitable for machine learning models.\n","- **Importance of preprocessing:**\n","  - Ensures models are accurate and reliable.\n","  - Prevents biased or misleading insights.\n","  - Improves performance of statistical and ML algorithms.\n"]},{"cell_type":"markdown","id":"d5331171-671d-4412-96c4-68a755b70943","metadata":{"id":"d5331171-671d-4412-96c4-68a755b70943"},"source":["# Missing Values\n","\n","- **Definition:** Missing values occur when no data value is recorded for a feature in an observation.\n","- **Causes:**\n","  - Human or data entry errors\n","  - Sensor or measurement errors\n","  - Incomplete surveys or logs\n","- **Problems caused by missing values:**\n","  - Biased statistical calculations\n","  - Poor machine learning model performance\n","- **Example:** In a survey dataset, some participants may not provide their age or income."]},{"cell_type":"markdown","id":"ca3a47eb-368c-448f-be3a-3d5618f042ab","metadata":{"id":"ca3a47eb-368c-448f-be3a-3d5618f042ab"},"source":["# Techniques to Handle Missing Values\n","\n","- **Deletion:**\n","  - Remove rows or columns containing missing values.\n","  - Simple but may lead to significant data loss.\n","- **Imputation:**\n","  - Fill missing values with statistical measures:\n","    - Mean or median for numerical columns\n","    - Mode for categorical columns\n","  - Advanced methods: KNN imputation, regression-based imputation.\n","- **Placeholder value:**\n","  - Replace missing categorical values with 'Unknown' or a special category.\n","- **Teaching tip:** Always evaluate the impact of missing data before choosing a technique."]},{"cell_type":"markdown","id":"ac37d2b2-1ce2-4b46-af8d-35e571f176df","metadata":{"id":"ac37d2b2-1ce2-4b46-af8d-35e571f176df"},"source":["# Outliers\n","\n","- **Definition:** Outliers are data points that are significantly different from other observations.\n","- **Causes:**\n","  - Measurement or data entry errors\n","  - Rare but valid natural events\n","- **Problems caused by outliers:**\n","  - Skew statistical measures like mean and standard deviation\n","  - Reduce accuracy of ML models sensitive to distance (e.g., linear regression, KNN)\n","- **Example:** In a salary dataset, a few extremely high salaries may distort the average salary."]},{"cell_type":"markdown","id":"e79d96e7-279f-4c00-9172-d7a6f9938581","metadata":{"id":"e79d96e7-279f-4c00-9172-d7a6f9938581"},"source":["# Techniques to Detect and Handle Outliers\n","\n","- **Detection methods:**\n","  - **IQR (Interquartile Range):** Values below Q1 - 1.5*IQR or above Q3 + 1.5*IQR are outliers.\n","  - **Z-score method:** Data points with z-score > 3 or < -3 are considered outliers.\n","  - **Visualization:** Use boxplots, histograms, or scatterplots to visually identify outliers.\n","- **Handling methods:**\n","  - **Removal:** Delete rows containing outliers.\n","  - **Transformation:** Apply log or square root to reduce the impact of extreme values.\n","  - **Capping / Flooring:** Replace extreme values with nearest acceptable value.\n","- **Teaching tip:** Outliers are not always errors—sometimes they provide important insights."]},{"cell_type":"markdown","id":"73956190-fe8e-40a1-b789-bdb17d035173","metadata":{"id":"73956190-fe8e-40a1-b789-bdb17d035173"},"source":["# Summary\n","\n","- Missing values and outliers are common in real-world datasets.\n","- Proper handling is crucial for:\n","  - Accurate statistics\n","  - Reliable machine learning models\n","  - Meaningful insights from data\n","- Key takeaways:\n","  - Missing values: deletion, imputation, or placeholder values\n","  - Outliers: detection using IQR or z-score, handling by removal, transformation, or capping\n","- Remember: Always analyze the dataset context before making preprocessing decisions."]},{"cell_type":"markdown","id":"12024869-925f-4a0e-b7ae-c1674b865bd7","metadata":{"id":"12024869-925f-4a0e-b7ae-c1674b865bd7"},"source":["# Missing Value and Outlier Handling\n","\n","In this section, we will implement data preprocessing techniques on our dataset:\n","\n","1. Load and explore the dataset.\n","2. Handle missing values.\n","3. Detect outliers in numerical columns.\n","4. Handle outliers by removal or capping.\n","5. Validate the cleaned dataset.\n","\n","We will use **classes and functions** with proper docstrings to make the code modular and professional.\n"]},{"cell_type":"markdown","id":"dee76e82-1524-4eed-a871-e9a4b7d9fff9","metadata":{"id":"dee76e82-1524-4eed-a871-e9a4b7d9fff9"},"source":["# Step 1: Loading and Exploring the Dataset\n","\n","In this step, we will:\n","- Import necessary Python libraries.\n","- Load the dataset (from Lab 4 or any CSV file) into a Pandas DataFrame.\n","- Explore the dataset by checking its shape, column types, and basic statistics.\n","- Identify numerical and categorical columns, and check for missing values."]},{"cell_type":"code","execution_count":1,"id":"9c9f51dc-6b5d-4fa0-bfc2-456f8efa164c","metadata":{"id":"9c9f51dc-6b5d-4fa0-bfc2-456f8efa164c","outputId":"ff848564-459b-4a87-e089-137ee24f8291","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759145902534,"user_tz":-330,"elapsed":2501,"user":{"displayName":"SWADHIN DAS","userId":"08011350409236666399"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset shape: (344, 7)\n","\n","Column names and data types:\n"," species               object\n","island                object\n","bill_length_mm       float64\n","bill_depth_mm        float64\n","flipper_length_mm    float64\n","body_mass_g          float64\n","sex                   object\n","dtype: object\n","\n","First five rows of the dataset:\n","   species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n","0  Adelie  Torgersen            39.1           18.7              181.0   \n","1  Adelie  Torgersen            39.5           17.4              186.0   \n","2  Adelie  Torgersen            40.3           18.0              195.0   \n","3  Adelie  Torgersen             NaN            NaN                NaN   \n","4  Adelie  Torgersen            36.7           19.3              193.0   \n","\n","   body_mass_g     sex  \n","0       3750.0    MALE  \n","1       3800.0  FEMALE  \n","2       3250.0  FEMALE  \n","3          NaN     NaN  \n","4       3450.0  FEMALE  \n","\n","Summary statistics of numerical columns:\n","        bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n","count      342.000000     342.000000         342.000000   342.000000\n","mean        43.921930      17.151170         200.915205  4201.754386\n","std          5.459584       1.974793          14.061714   801.954536\n","min         32.100000      13.100000         172.000000  2700.000000\n","25%         39.225000      15.600000         190.000000  3550.000000\n","50%         44.450000      17.300000         197.000000  4050.000000\n","75%         48.500000      18.700000         213.000000  4750.000000\n","max         59.600000      21.500000         231.000000  6300.000000\n","\n","Numerical columns: ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n","Categorical columns: ['species', 'island', 'sex']\n","\n","Missing values per column:\n"," species               0\n","island                0\n","bill_length_mm        2\n","bill_depth_mm         2\n","flipper_length_mm     2\n","body_mass_g           2\n","sex                  11\n","dtype: int64\n"]}],"source":["# Step 1: Import libraries and load dataset\n","import pandas as pd\n","import numpy as np\n","\n","# Optional: visualization libraries\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Load Penguins dataset from URL\n","url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv\"\n","df = pd.read_csv(url)\n","\n","# Basic exploration\n","print(\"Dataset shape:\", df.shape)\n","print(\"\\nColumn names and data types:\\n\", df.dtypes)\n","print(\"\\nFirst five rows of the dataset:\\n\", df.head())\n","print(\"\\nSummary statistics of numerical columns:\\n\", df.describe())\n","\n","# Identify numerical and categorical columns\n","numerical_cols = df.select_dtypes(include='number').columns.tolist()\n","categorical_cols = df.select_dtypes(include='object').columns.tolist()\n","print(\"\\nNumerical columns:\", numerical_cols)\n","print(\"Categorical columns:\", categorical_cols)\n","\n","# Check for missing values\n","print(\"\\nMissing values per column:\\n\", df.isnull().sum())"]},{"cell_type":"markdown","id":"fd945c62-6241-4258-8217-d38eaefdc906","metadata":{"id":"fd945c62-6241-4258-8217-d38eaefdc906"},"source":["# Step 2: Handling Missing Values\n","\n","In this step, we will handle missing values in the dataset.\n","\n","- Identify columns with missing data.\n","- For **numerical columns**, we will fill missing values using the **mean** of the column.\n","- For **categorical columns**, we will fill missing values using a **placeholder value** ('Unknown').\n","- We will implement this in a **class-based approach** with proper docstrings, so it can be reused for other datasets.\n","- After handling, we will verify that there are no missing values left."]},{"cell_type":"code","execution_count":2,"id":"bc3ceefb-6b75-43f0-892a-b0d711fca826","metadata":{"id":"bc3ceefb-6b75-43f0-892a-b0d711fca826","executionInfo":{"status":"ok","timestamp":1759145902562,"user_tz":-330,"elapsed":17,"user":{"displayName":"SWADHIN DAS","userId":"08011350409236666399"}}},"outputs":[],"source":["class MissingValueHandler:\n","    \"\"\"\n","    A class to handle missing values in a dataset.\n","\n","    Methods:\n","    --------\n","    handle_numerical(df, numerical_cols)\n","        Fills missing numerical values with the column mean.\n","\n","    handle_categorical(df, categorical_cols, placeholder='Unknown')\n","        Fills missing categorical values with a placeholder value.\n","    \"\"\"\n","\n","    def handle_numerical(self, df, numerical_cols):\n","        \"\"\"\n","        Fill missing values in numerical columns with the column mean.\n","\n","        Parameters:\n","        -----------\n","        df : pandas.DataFrame\n","            Dataset containing numerical columns.\n","        numerical_cols : list\n","            List of numerical column names.\n","\n","        Returns:\n","        --------\n","        pandas.DataFrame\n","            Dataset with missing numerical values filled.\n","        \"\"\"\n","        for col in numerical_cols:\n","            mean_val = df[col].mean()\n","            df[col] = df[col].fillna(mean_val)\n","        return df\n","\n","    def handle_categorical(self, df, categorical_cols, placeholder='Unknown'):\n","        \"\"\"\n","        Fill missing values in categorical columns with a placeholder.\n","\n","        Parameters:\n","        -----------\n","        df : pandas.DataFrame\n","            Dataset containing categorical columns.\n","        categorical_cols : list\n","            List of categorical column names.\n","        placeholder : str\n","            Value to fill missing categorical data with (default 'Unknown').\n","\n","        Returns:\n","        --------\n","        pandas.DataFrame\n","            Dataset with missing categorical values filled.\n","        \"\"\"\n","        for col in categorical_cols:\n","            df[col] = df[col].fillna(placeholder)\n","        return df"]},{"cell_type":"code","execution_count":3,"id":"e419a9b5-4fb4-4b66-bd98-193e56d92f12","metadata":{"id":"e419a9b5-4fb4-4b66-bd98-193e56d92f12","outputId":"21c71e0f-c89e-46df-da61-bf4c744fc208","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759145902609,"user_tz":-330,"elapsed":34,"user":{"displayName":"SWADHIN DAS","userId":"08011350409236666399"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Missing values after handling:\n"," species              0\n","island               0\n","bill_length_mm       0\n","bill_depth_mm        0\n","flipper_length_mm    0\n","body_mass_g          0\n","sex                  0\n","dtype: int64\n"]}],"source":["# Create object and handle missing values\n","mv_handler = MissingValueHandler()\n","\n","# Handle numerical columns\n","df = mv_handler.handle_numerical(df, numerical_cols)\n","\n","# Handle categorical columns\n","df = mv_handler.handle_categorical(df, categorical_cols)\n","\n","# Class-level docstring explanation for lab context\n","\"\"\"\n","The 'MissingValueHandler' class preprocesses datasets by handling missing values.\n","Numerical columns are filled with mean values, and categorical columns are filled with a placeholder.\n","This ensures the dataset has no missing values and is ready for further analysis.\n","\"\"\"\n","\n","# Verify missing values handled\n","print(\"\\nMissing values after handling:\\n\", df.isnull().sum())"]},{"cell_type":"markdown","id":"b05bed49-2ba2-424f-9350-37d2eb714e59","metadata":{"id":"b05bed49-2ba2-424f-9350-37d2eb714e59"},"source":["# Step 3: Detecting Outliers\n","\n","In this step, we will identify outliers in the dataset.\n","\n","- Outliers are data points significantly different from the rest of the data.\n","- Problems caused by outliers:\n","  - Skew statistical measures like mean and standard deviation\n","  - Reduce accuracy of machine learning models\n","- We will use the **Interquartile Range (IQR)** method:\n","  - Q1 = 25% percentile, Q3 = 75% percentile\n","  - IQR = Q3 - Q1\n","  - Any value below Q1 - 1.5*IQR or above Q3 + 1.5*IQR is considered an outlier\n","- We will implement this in a **class-based approach** with proper docstrings."]},{"cell_type":"code","execution_count":4,"id":"b295e1e3-224a-40c1-9a6f-fe26ba4da987","metadata":{"id":"b295e1e3-224a-40c1-9a6f-fe26ba4da987","executionInfo":{"status":"ok","timestamp":1759145902629,"user_tz":-330,"elapsed":12,"user":{"displayName":"SWADHIN DAS","userId":"08011350409236666399"}}},"outputs":[],"source":["class OutlierDetection:\n","    \"\"\"\n","    A class to detect outliers in numerical columns of a dataset using the IQR method.\n","\n","    Methods:\n","    --------\n","    detect_outliers(df, numerical_cols)\n","        Returns a dictionary containing outlier indices for each numerical column.\n","    \"\"\"\n","\n","    def detect_outliers(self, df, numerical_cols):\n","        \"\"\"\n","        Detect outliers in numerical columns using the IQR method.\n","\n","        Parameters:\n","        -----------\n","        df : pandas.DataFrame\n","            Dataset containing numerical columns.\n","        numerical_cols : list\n","            List of numerical column names.\n","\n","        Returns:\n","        --------\n","        dict\n","            Dictionary where keys are column names and values are lists of outlier row indices.\n","        \"\"\"\n","        outlier_indices = {}\n","        for col in numerical_cols:\n","            Q1 = df[col].quantile(0.25)\n","            Q3 = df[col].quantile(0.75)\n","            IQR = Q3 - Q1\n","            lower_bound = Q1 - 1.5 * IQR\n","            upper_bound = Q3 + 1.5 * IQR\n","            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index.tolist()\n","            outlier_indices[col] = outliers\n","        return outlier_indices"]},{"cell_type":"code","execution_count":5,"id":"7690258e-6c19-420a-9df3-b72a3e60b89f","metadata":{"id":"7690258e-6c19-420a-9df3-b72a3e60b89f","outputId":"2fb7cd27-8937-490a-808d-e084065a3e2f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759145902673,"user_tz":-330,"elapsed":43,"user":{"displayName":"SWADHIN DAS","userId":"08011350409236666399"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Column 'bill_length_mm' has 0 outlier(s) at indices: []\n","Column 'bill_depth_mm' has 0 outlier(s) at indices: []\n","Column 'flipper_length_mm' has 0 outlier(s) at indices: []\n","Column 'body_mass_g' has 0 outlier(s) at indices: []\n"]}],"source":["# Create object and detect outliers\n","outlier_detector = OutlierDetection()\n","outliers_dict = outlier_detector.detect_outliers(df, numerical_cols)\n","\n","# Class-level docstring explanation for lab context\n","\"\"\"\n","The 'OutlierDetection' class identifies outliers in numerical columns using the IQR method.\n","It returns the indices of rows containing outlier values for each column.\n","This allows us to decide how to handle them in the next preprocessing step.\n","\"\"\"\n","\n","# Display outliers per numerical column\n","for col, indices in outliers_dict.items():\n","    print(f\"Column '{col}' has {len(indices)} outlier(s) at indices: {indices}\")"]},{"cell_type":"markdown","id":"5cfdb608-f198-47ff-bf48-6f6d90cf91d8","metadata":{"id":"5cfdb608-f198-47ff-bf48-6f6d90cf91d8"},"source":["# Step 4: Handling Outliers\n","\n","In this step, we will preprocess the dataset to handle outliers.\n","\n","- Outliers can distort statistical analysis and reduce machine learning model performance.\n","- Common handling techniques:\n","  - **Removal:** Delete rows containing outliers.\n","  - **Capping/Flooring:** Replace extreme values with nearest acceptable values.\n","- We will implement **outlier removal** using a class-based approach.\n","- After handling, we will verify that the dataset is cleaned of extreme values."]},{"cell_type":"code","execution_count":6,"id":"cbb489f2-5e61-4307-9927-e45cb78795dc","metadata":{"id":"cbb489f2-5e61-4307-9927-e45cb78795dc","executionInfo":{"status":"ok","timestamp":1759145902681,"user_tz":-330,"elapsed":9,"user":{"displayName":"SWADHIN DAS","userId":"08011350409236666399"}}},"outputs":[],"source":["class OutlierHandler:\n","    \"\"\"\n","    A class to handle outliers in numerical columns of a dataset.\n","\n","    Methods:\n","    --------\n","    remove_outliers(df, numerical_cols)\n","        Removes rows containing outliers in any numerical column using the IQR method.\n","    \"\"\"\n","\n","    def remove_outliers(self, df, numerical_cols):\n","        \"\"\"\n","        Remove rows containing outliers based on the IQR method.\n","\n","        Parameters:\n","        -----------\n","        df : pandas.DataFrame\n","            Dataset containing numerical columns.\n","        numerical_cols : list\n","            List of numerical column names.\n","\n","        Returns:\n","        --------\n","        pandas.DataFrame\n","            Dataset with rows containing outliers removed.\n","        \"\"\"\n","        outlier_indices = set()\n","        for col in numerical_cols:\n","            Q1 = df[col].quantile(0.25)\n","            Q3 = df[col].quantile(0.75)\n","            IQR = Q3 - Q1\n","            lower_bound = Q1 - 1.5 * IQR\n","            upper_bound = Q3 + 1.5 * IQR\n","            indices = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index\n","            outlier_indices.update(indices)\n","        df_clean = df.drop(index=outlier_indices)\n","        return df_clean"]},{"cell_type":"code","execution_count":7,"id":"365aec44-f6ed-451a-a399-84a9b09fc5e9","metadata":{"id":"365aec44-f6ed-451a-a399-84a9b09fc5e9","outputId":"8a524ca7-2d53-4ad9-e391-f4729e4fbafd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759145902737,"user_tz":-330,"elapsed":55,"user":{"displayName":"SWADHIN DAS","userId":"08011350409236666399"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Original dataset shape: (344, 7)\n","Dataset shape after removing outliers: (344, 7)\n","\n","First five rows after outlier handling:\n","   species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n","0  Adelie  Torgersen        39.10000       18.70000         181.000000   \n","1  Adelie  Torgersen        39.50000       17.40000         186.000000   \n","2  Adelie  Torgersen        40.30000       18.00000         195.000000   \n","3  Adelie  Torgersen        43.92193       17.15117         200.915205   \n","4  Adelie  Torgersen        36.70000       19.30000         193.000000   \n","\n","   body_mass_g      sex  \n","0  3750.000000     MALE  \n","1  3800.000000   FEMALE  \n","2  3250.000000   FEMALE  \n","3  4201.754386  Unknown  \n","4  3450.000000   FEMALE  \n"]}],"source":["# Create object and remove outliers\n","outlier_handler = OutlierHandler()\n","df_clean = outlier_handler.remove_outliers(df, numerical_cols)\n","\n","# Class-level docstring explanation for lab context\n","\"\"\"\n","The 'OutlierHandler' class removes rows containing outliers in numerical columns using the IQR method.\n","This ensures the dataset is cleaned and ready for further analysis or machine learning tasks.\n","\"\"\"\n","\n","# Verify dataset after outlier removal\n","print(\"Original dataset shape:\", df.shape)\n","print(\"Dataset shape after removing outliers:\", df_clean.shape)\n","print(\"\\nFirst five rows after outlier handling:\\n\", df_clean.head())"]},{"cell_type":"markdown","id":"02df3dd6-82ca-456f-a0ad-63c966188487","metadata":{"id":"02df3dd6-82ca-456f-a0ad-63c966188487"},"source":["# Step 5: Validation of Preprocessed Dataset\n","\n","In this step, we will validate the dataset after handling missing values and outliers:\n","\n","- Verify that there are **no missing values** left.\n","- Check that **outliers have been removed**.\n","- Inspect the **shape of the dataset**.\n","- Preview the **first few rows** to ensure data integrity.\n","- This ensures the dataset is ready for further analysis or machine learning tasks."]},{"cell_type":"code","execution_count":8,"id":"3ca74031-d412-445a-b28b-d9a1b3a8b1d1","metadata":{"id":"3ca74031-d412-445a-b28b-d9a1b3a8b1d1","outputId":"67702410-3c1e-4e91-d143-f3c40e8a3680","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759145902762,"user_tz":-330,"elapsed":28,"user":{"displayName":"SWADHIN DAS","userId":"08011350409236666399"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Missing values per column:\n"," species              0\n","island               0\n","bill_length_mm       0\n","bill_depth_mm        0\n","flipper_length_mm    0\n","body_mass_g          0\n","sex                  0\n","dtype: int64\n","\n","Shape of the cleaned dataset: (344, 7)\n","\n","First five rows of the cleaned dataset:\n","   species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n","0  Adelie  Torgersen        39.10000       18.70000         181.000000   \n","1  Adelie  Torgersen        39.50000       17.40000         186.000000   \n","2  Adelie  Torgersen        40.30000       18.00000         195.000000   \n","3  Adelie  Torgersen        43.92193       17.15117         200.915205   \n","4  Adelie  Torgersen        36.70000       19.30000         193.000000   \n","\n","   body_mass_g      sex  \n","0  3750.000000     MALE  \n","1  3800.000000   FEMALE  \n","2  3250.000000   FEMALE  \n","3  4201.754386  Unknown  \n","4  3450.000000   FEMALE  \n","\n","Summary statistics of cleaned numerical columns:\n","        bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n","count      344.000000     344.000000         344.000000   344.000000\n","mean        43.921930      17.151170         200.915205  4201.754386\n","std          5.443643       1.969027          14.020657   799.613058\n","min         32.100000      13.100000         172.000000  2700.000000\n","25%         39.275000      15.600000         190.000000  3550.000000\n","50%         44.250000      17.300000         197.000000  4050.000000\n","75%         48.500000      18.700000         213.000000  4750.000000\n","max         59.600000      21.500000         231.000000  6300.000000\n"]}],"source":["# Check for missing values\n","print(\"Missing values per column:\\n\", df_clean.isnull().sum())\n","\n","# Check dataset shape\n","print(\"\\nShape of the cleaned dataset:\", df_clean.shape)\n","\n","# Preview first five rows\n","print(\"\\nFirst five rows of the cleaned dataset:\\n\", df_clean.head())\n","\n","# Optional: basic statistics to ensure values are reasonable\n","print(\"\\nSummary statistics of cleaned numerical columns:\\n\", df_clean[numerical_cols].describe())"]},{"cell_type":"markdown","id":"1a675729-0274-4fc2-9178-65ccae2f2afe","metadata":{"id":"1a675729-0274-4fc2-9178-65ccae2f2afe"},"source":["# Step 6: Feature Scaling\n","\n","In this step, we will preprocess the dataset to make it ready for machine learning models:\n","\n","- **Feature Scaling:**  \n","  - Ensures numerical features are on a similar scale.  \n","  - Common techniques:  \n","    - **Min-Max Scaling** (scales values between 0–1).  \n","    - **Standardization** (transforms data to mean=0 and std=1).  \n","    - **Robust Scaling** (uses median and IQR, less sensitive to outliers).  \n","    - **Max-Abs Scaling** (scales values between -1 and 1).  \n","  - Scaling is important for distance-based models (KNN, SVM, Neural Networks) and models sensitive to feature magnitude.\n","\n","- We will implement these scaling techniques in a **class-based approach** with proper docstrings."]},{"cell_type":"markdown","source":[],"metadata":{"id":"m1DK-Is-Ul12"},"id":"m1DK-Is-Ul12"},{"cell_type":"code","execution_count":9,"id":"aa0fc6a2-b68f-4904-bd30-d7a5feed264d","metadata":{"id":"aa0fc6a2-b68f-4904-bd30-d7a5feed264d","executionInfo":{"status":"ok","timestamp":1759145902934,"user_tz":-330,"elapsed":136,"user":{"displayName":"SWADHIN DAS","userId":"08011350409236666399"}}},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler\n","\n","class FeaturePreprocessor:\n","    \"\"\"\n","    A class to perform feature scaling on a dataset.\n","\n","    Methods:\n","    --------\n","    scale_features(df, numerical_cols, method='minmax')\n","        Scales numerical features using one of the following methods:\n","        - 'minmax': Min-Max Scaling\n","        - 'standard': Standardization (Z-score Scaling)\n","        - 'robust': Robust Scaling (median and IQR)\n","        - 'maxabs': Max-Abs Scaling\n","    \"\"\"\n","\n","    def scale_features(self, df, numerical_cols, method='minmax'):\n","        \"\"\"\n","        Scale numerical columns using the specified method.\n","\n","        Parameters:\n","        -----------\n","        df : pandas.DataFrame\n","            Dataset containing numerical columns.\n","        numerical_cols : list\n","            List of numerical column names.\n","        method : str\n","            Scaling method: 'minmax', 'standard', 'robust', or 'maxabs'.\n","\n","        Returns:\n","        --------\n","        pandas.DataFrame\n","            Dataset with scaled numerical features.\n","        \"\"\"\n","        if method == 'minmax':\n","            scaler = MinMaxScaler()\n","        elif method == 'standard':\n","            scaler = StandardScaler()\n","        elif method == 'robust':\n","            scaler = RobustScaler()\n","        elif method == 'maxabs':\n","            scaler = MaxAbsScaler()\n","        else:\n","            raise ValueError(\"Method must be 'minmax', 'standard', 'robust', or 'maxabs'\")\n","\n","        df_scaled = df.copy()\n","        df_scaled[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n","        return df_scaled"]},{"cell_type":"code","execution_count":21,"id":"503225c3-f724-4e33-9e35-a4de477d6106","metadata":{"id":"503225c3-f724-4e33-9e35-a4de477d6106","outputId":"e4d1eb16-a09d-4bfb-b650-c1686955e800","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759146630572,"user_tz":-330,"elapsed":40,"user":{"displayName":"SWADHIN DAS","userId":"08011350409236666399"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Min-Max Scaling (first 5 rows):\n","    bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n","0        0.254545       0.666667           0.152542     0.291667\n","1        0.269091       0.511905           0.237288     0.305556\n","2        0.298182       0.583333           0.389831     0.152778\n","3        0.429888       0.482282           0.490088     0.417154\n","4        0.167273       0.738095           0.355932     0.208333 \n","\n","Standard Scaling (first 5 rows):\n","    bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n","0   -8.870812e-01   7.877425e-01          -1.422488    -0.565789\n","1   -8.134940e-01   1.265563e-01          -1.065352    -0.503168\n","2   -6.663195e-01   4.317192e-01          -0.422507    -1.192003\n","3   -1.307172e-15   1.806927e-15           0.000000     0.000000\n","4   -1.328605e+00   1.092905e+00          -0.565361    -0.941517 \n","\n","Robust Scaling (first 5 rows):\n","    bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n","0       -0.558266       0.451613          -0.695652    -0.250000\n","1       -0.514905       0.032258          -0.478261    -0.208333\n","2       -0.428184       0.225806          -0.086957    -0.666667\n","3       -0.035563      -0.048010           0.170226     0.126462\n","4       -0.818428       0.645161          -0.173913    -0.500000 \n","\n","Max-Abs Scaling (first 5 rows):\n","    bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n","0        0.656040       0.869767           0.783550     0.595238\n","1        0.662752       0.809302           0.805195     0.603175\n","2        0.676174       0.837209           0.844156     0.515873\n","3        0.736945       0.797729           0.869763     0.666945\n","4        0.615772       0.897674           0.835498     0.547619 \n","\n"]}],"source":["# Create object and preprocess features\n","preprocessor = FeaturePreprocessor()\n","\n","# Apply different scaling methods on numerical columns\n","df_minmax = preprocessor.scale_features(df_clean, numerical_cols, method='minmax')\n","df_standard = preprocessor.scale_features(df_clean, numerical_cols, method='standard')\n","df_robust = preprocessor.scale_features(df_clean, numerical_cols, method='robust')\n","df_maxabs = preprocessor.scale_features(df_clean, numerical_cols, method='maxabs')\n","\n","# Class-level docstring explanation for lab context\n","\"\"\"\n","The 'FeaturePreprocessor' class applies four types of scaling techniques\n","(Min-Max, Standard, Robust, Max-Abs) on numerical features.\n","This ensures that data is transformed into a suitable range or distribution,\n","making it ready for machine learning models.\n","\"\"\"\n","\n","# Verify scaled datasets\n","print(\"Min-Max Scaling (first 5 rows):\\n\", df_minmax[numerical_cols].head(), \"\\n\")\n","print(\"Standard Scaling (first 5 rows):\\n\", df_standard[numerical_cols].head(), \"\\n\")\n","print(\"Robust Scaling (first 5 rows):\\n\", df_robust[numerical_cols].head(), \"\\n\")\n","print(\"Max-Abs Scaling (first 5 rows):\\n\", df_maxabs[numerical_cols].head(), \"\\n\")"]},{"cell_type":"markdown","id":"33e59113-5132-431c-a061-ecb77eb448e1","metadata":{"id":"33e59113-5132-431c-a061-ecb77eb448e1"},"source":["# Test Case 1: Fill Missing Values in Numerical Column\n","\n","- Dataset contains a numerical column with missing values.\n","- Task: Use `MissingValueHandler` to fill missing values with the column mean."]},{"cell_type":"code","execution_count":23,"id":"b40100a5-2ce4-4eb7-9dc8-376eacb7f719","metadata":{"id":"b40100a5-2ce4-4eb7-9dc8-376eacb7f719","outputId":"23670d3d-b8ed-48c8-8dbd-adf6e67226ce","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759146981270,"user_tz":-330,"elapsed":20,"user":{"displayName":"SWADHIN DAS","userId":"08011350409236666399"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["    Age\n","0  25.0\n","1   NaN\n","2  30.0\n","3  22.0\n","4   NaN\n","         Age\n","0  25.000000\n","1  25.666667\n","2  30.000000\n","3  22.000000\n","4  25.666667\n"]}],"source":["# Sample dataset\n","df_test1 = pd.DataFrame({\n","    'Age': [25, np.nan, 30, 22, np.nan]\n","})\n","\n","# Handle missing values\n","mv_handler_test = MissingValueHandler()\n","print(df_test1)\n","df_test2 = mv_handler_test.handle_numerical(df_test1, ['Age'])\n","print(df_test2)"]},{"cell_type":"markdown","id":"50e7204d-9c49-4018-9c65-29637eb03d6b","metadata":{"id":"50e7204d-9c49-4018-9c65-29637eb03d6b"},"source":["# Test Case 2: Fill Missing Values in Categorical Column\n","\n","- Dataset contains a categorical column with missing values.\n","- Task: Use `MissingValueHandler` to fill missing values with 'Unknown'."]},{"cell_type":"code","execution_count":27,"id":"6b6abb24-eda3-4064-9ee8-8347a2c92277","metadata":{"id":"6b6abb24-eda3-4064-9ee8-8347a2c92277","outputId":"8c0f3008-9691-49b2-c14d-921afa82b341","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759147095619,"user_tz":-330,"elapsed":10,"user":{"displayName":"SWADHIN DAS","userId":"08011350409236666399"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["     Species\n","0     Adelie\n","1       None\n","2  Chinstrap\n","3       None\n","\n","\n","\n","     Species\n","0     Adelie\n","1    Unknown\n","2  Chinstrap\n","3    Unknown\n"]}],"source":["df_test3 = pd.DataFrame({\n","    'Species': ['Adelie', None, 'Chinstrap', None]\n","})\n","\n","# Handle missing values\n","print(df_test3)\n","df_test4 = mv_handler_test.handle_categorical(df_test3, ['Species'])\n","print(\"\\n\\n\")\n","print(df_test4)"]},{"cell_type":"markdown","id":"7b7ed91a-df18-4bdb-bd87-7b95eaefec42","metadata":{"id":"7b7ed91a-df18-4bdb-bd87-7b95eaefec42"},"source":["# Test Case 3: Detect Outliers in Numerical Column\n","\n","- Dataset contains a numerical column with extreme values.\n","- Task: Use `OutlierDetection` to identify outliers using IQR."]},{"cell_type":"code","execution_count":29,"id":"94108bab-aeb1-4600-bae8-2fd6853263a2","metadata":{"id":"94108bab-aeb1-4600-bae8-2fd6853263a2","outputId":"9cadaa6a-e6b1-41b5-9c9c-6365d33d4eb8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759147218818,"user_tz":-330,"elapsed":14,"user":{"displayName":"SWADHIN DAS","userId":"08011350409236666399"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["{'Salary': [3, 6]}\n"]}],"source":["df_test5 = pd.DataFrame({\n","    'Salary': [30000, 32000, 31000, 1000000, 33000, 35000, 100]\n","})\n","\n","outlier_detector_test = OutlierDetection()\n","outliers_test3 = outlier_detector_test.detect_outliers(df_test5, ['Salary'])\n","print(outliers_test3)"]},{"cell_type":"markdown","id":"ca71f100-82c3-46fd-9d1a-eddd9292b082","metadata":{"id":"ca71f100-82c3-46fd-9d1a-eddd9292b082"},"source":["# Test Case 4: Remove Outliers from Numerical Column\n","\n","- Dataset contains outliers in a numerical column.\n","- Task: Use `OutlierHandler` to remove rows containing outliers."]},{"cell_type":"code","execution_count":14,"id":"a91d1c10-e069-4198-a8d4-053f4e001cf8","metadata":{"id":"a91d1c10-e069-4198-a8d4-053f4e001cf8","outputId":"471f3f7e-1e35-4380-de95-ba9435f6a078","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759145903113,"user_tz":-330,"elapsed":5,"user":{"displayName":"SWADHIN DAS","userId":"08011350409236666399"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["   Salary\n","0   30000\n","1   32000\n","2   31000\n","4   33000\n","5   35000\n"]}],"source":["outlier_handler_test = OutlierHandler()\n","df_test4_clean = outlier_handler_test.remove_outliers(df_test3, ['Salary'])\n","print(df_test4_clean)"]},{"cell_type":"markdown","id":"f9f47591-953b-4087-991f-ec9ed41c406d","metadata":{"id":"f9f47591-953b-4087-991f-ec9ed41c406d"},"source":["# Test Case 5: Scale Numerical Features\n","\n","- Dataset contains numerical features with different ranges.\n","- Task: Use `FeaturePreprocessor` to scale numerical columns using Min-Max scaling."]},{"cell_type":"code","execution_count":31,"id":"51ba6ddb-c3c1-403f-8131-16082b569e7c","metadata":{"id":"51ba6ddb-c3c1-403f-8131-16082b569e7c","outputId":"5085d3ab-5848-4443-a64a-4328db9e8e8f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759147434596,"user_tz":-330,"elapsed":20,"user":{"displayName":"SWADHIN DAS","userId":"08011350409236666399"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["     Height  Weight\n","0  0.000000    0.00\n","1  0.333333    0.25\n","2  0.666667    0.50\n","3  1.000000    1.00\n"]}],"source":["df_test5 = pd.DataFrame({\n","    'Height': [150, 160, 170, 180],\n","    'Weight': [50, 60, 70, 90]\n","})\n","\n","preprocessor_test = FeaturePreprocessor()\n","df_test5_scaled = preprocessor_test.scale_features(df_test5, ['Height', 'Weight'], method='minmax')\n","print(df_test5_scaled)"]},{"cell_type":"markdown","id":"47cff9b1-1f2e-41cb-961e-98bf83f944ab","metadata":{"id":"47cff9b1-1f2e-41cb-961e-98bf83f944ab"},"source":["# Experiment 6 Summary and Future Classes\n","\n","## Summary of Experiment 6: Data Preprocessing\n","\n","In this experiment, we focused on preprocessing a dataset to make it ready for analysis or machine learning tasks. The main steps included:\n","\n","1. **Loading and Exploring the Dataset**\n","   - Imported the dataset and examined its structure, column types, and missing values.\n","   - Identified numerical and categorical columns.\n","\n","2. **Handling Missing Values**\n","   - Implemented a `MissingValueHandler` class to fill missing numerical values with the mean and categorical values with a placeholder.\n","   - Verified that the dataset had no missing values after preprocessing.\n","\n","3. **Detecting Outliers**\n","   - Implemented an `OutlierDetection` class using the Interquartile Range (IQR) method.\n","   - Identified outliers in numerical columns to prevent skewed analysis.\n","\n","4. **Handling Outliers**\n","   - Implemented an `OutlierHandler` class to remove rows containing outliers.\n","   - Ensured the dataset was clean and robust for further processing.\n","\n","5. **Validation**\n","   - Verified the dataset for missing values and outliers.\n","   - Checked the dataset shape and previewed first few rows to ensure data integrity.\n","\n","6. **Feature Scaling**\n","   - Implemented a `FeaturePreprocessor` class to scale numerical features (like Min-Max scaling).\n","   - Produced a fully numeric, scaled dataset ready for machine learning models.\n","\n","7. **Test Cases**\n","   - Practiced preprocessing tasks on small datasets to reinforce concepts.\n","   - Covered missing value handling, outlier detection/removal, scaling, and encoding.\n","\n","---\n","\n","## Future Classes / Extensions\n","\n","- **Advanced Feature Engineering**\n","  - Creating new features from existing ones to improve model performance.\n","  - Handling date/time or text features.\n","\n","- **Dimensionality Reduction**\n","  - Techniques like PCA or t-SNE to reduce feature space.\n","\n","- **Encoding for High Cardinality Features**\n","  - Target encoding, frequency encoding for categorical features with many levels.\n","\n","- **Automated Preprocessing Pipelines**\n","  - Using `scikit-learn` Pipelines to combine preprocessing steps and model training seamlessly.\n","\n","- **Handling Imbalanced Data**\n","  - Techniques like SMOTE, oversampling, or undersampling.\n","\n","These extensions will build on the preprocessing foundations learned in this experiment and prepare the dataset for robust machine learning workflows."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}